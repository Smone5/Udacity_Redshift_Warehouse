{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# ETL Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import configparser\n",
    "import psycopg2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/workspace'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# move up one directory for config files\n",
    "os.chdir('..')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Load configuration file\n",
    "\n",
    "config = configparser.ConfigParser()\n",
    "config.read('dwh.cfg')\n",
    "    \n",
    "host = config['CLUSTER']['DB_ENDPOINT']\n",
    "dbname = config['CLUSTER']['DB_NAME']\n",
    "user = config['CLUSTER']['DB_USER']\n",
    "password = config['CLUSTER']['DB_PASSWORD']\n",
    "port = config['CLUSTER']['DB_PORT']\n",
    "\n",
    "conn = psycopg2.connect(\"host={} dbname={} user={} password={} port={}\".format(host, dbname, user, password, port))\n",
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Load configuration variables\n",
    "\n",
    "iam_role = config['IAM_ROLE']['ARN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Create Staging Table SQL Queries\n",
    "\n",
    "staging_events_copy = (\"\"\"\n",
    "copy event_stage\n",
    "from 's3://udacity-dend/log_data/2018/11/2018'\n",
    "credentials 'aws_iam_role={}'\n",
    "format as json 's3://udacity-dend/log_json_path.json';\n",
    "\"\"\").format(iam_role)\n",
    "\n",
    "\n",
    "\n",
    "staging_songs_copy = (\"\"\"\n",
    "copy song_stage\n",
    "from 's3://udacity-dend/song_data/'\n",
    "credentials 'aws_iam_role={}'\n",
    "format as json 'auto';\n",
    "\"\"\").format(iam_role)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Staging Tables...\n"
     ]
    }
   ],
   "source": [
    "# Execute Staging Table SQL Queries \n",
    "copy_table_queries = [staging_events_copy, staging_songs_copy]\n",
    "print(\"Loading Staging Tables...\")\n",
    "for query in copy_table_queries:\n",
    "    cur.execute(query)\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Create Star Schema Table SQL Queries\n",
    "\n",
    "songplay_table_insert = (\"\"\"\n",
    "INSERT INTO fact_songplay(songplay_id, start_time, user_id, level, song_id, artist_id, session_id, location, user_agent)\n",
    "SELECT\n",
    "    e.userId || e.sessionId || e.itemInSession as songplay_id,\n",
    "    CAST(e.ts as bigint) as start_time,\n",
    "    CAST(e.userId as int) as user_id,\n",
    "    e.level as level,\n",
    "    st.song_id,\n",
    "    st.artist_id,\n",
    "    CAST(e.itemInSession as int) as session_id,\n",
    "    e.location as location,\n",
    "    e.userAgent as user_agent\n",
    "FROM (select * from event_stage where page = 'NextSong') as e\n",
    "LEFT JOIN (select distinct title, artist_name, artist_id, duration, song_id from song_stage) as st\n",
    "    ON ( e.song = st.title and e.artist = st.artist_name and e.length = st.duration)\n",
    "ORDER BY start_time ASC\n",
    "\"\"\")\n",
    "\n",
    "user_table_insert = (\"\"\"\n",
    "INSERT INTO dim_user (user_id, first_name, last_name, gender, level)\n",
    "SELECT DISTINCT\n",
    "    CAST(e.userID as integer) AS user_id,\n",
    "    e.firstName AS first_name,\n",
    "    e.lastName AS last_name,\n",
    "    e.gender AS gender,\n",
    "    e.level AS level\n",
    "FROM event_stage e\n",
    "WHERE e.page = 'NextSong'\n",
    "\"\"\")\n",
    "\n",
    "song_table_insert = (\"\"\"\n",
    "INSERT INTO dim_song (song_id, title, artist_id, year, duration)\n",
    "SELECT DISTINCT\n",
    "    s.song_id AS song_id,\n",
    "    s.title AS title,\n",
    "    s.artist_id AS artist_id,\n",
    "    CAST(s.year as integer) AS year,\n",
    "    CAST(s.duration as decimal(8,2)) AS duration\n",
    "FROM song_stage s\n",
    "\"\"\")\n",
    "\n",
    "artist_table_insert = (\"\"\"\n",
    "INSERT INTO dim_artist (artist_id, name, location, latitude, longitude)\n",
    "SELECT DISTINCT\n",
    "    s.artist_id AS artist_id,\n",
    "    s.artist_name AS name,\n",
    "    s.artist_location AS location,\n",
    "    CONVERT(float, s.artist_latitude) AS latitude,\n",
    "    CONVERT(float, s.artist_longitude) AS longitude\n",
    "FROM song_stage s\n",
    "JOIN event_stage e\n",
    "    ON (e.artist = s.artist_name AND e.song = s.title)\n",
    "WHERE e.page = 'NextSong'\n",
    "\"\"\")\n",
    "\n",
    "time_table_insert = (\"\"\"\n",
    "INSERT INTO dim_time(time_key, start_time, hour, day, week, month, year, weekday)\n",
    "SELECT DISTINCT\n",
    "    CAST(e.ts as bigint) AS time_key,\n",
    "    TIMESTAMP 'epoch' + e.ts/1000 *INTERVAL '1 second' as start_time,\n",
    "    EXTRACT(hour from TIMESTAMP 'epoch' + e.ts/1000 *INTERVAL '1 second') AS hour,\n",
    "    CAST(DATE_PART(day, TIMESTAMP 'epoch' + e.ts/1000 *INTERVAL '1 second')  as Integer) AS day,\n",
    "    CAST(DATE_PART(week, TIMESTAMP 'epoch' + e.ts/1000 *INTERVAL '1 second') as Integer) AS week,\n",
    "    CAST(DATE_PART(month, TIMESTAMP 'epoch' + e.ts/1000 *INTERVAL '1 second') as Integer) AS month,\n",
    "    CAST(DATE_PART(year, TIMESTAMP 'epoch' + e.ts/1000 *INTERVAL '1 second') as Integer) AS year,\n",
    "    CASE\n",
    "        WHEN(\n",
    "                DATE_PART(dayofweek, TIMESTAMP 'epoch' + e.ts/1000 *INTERVAL '1 second') = 0.0\n",
    "                OR\n",
    "                DATE_PART(dayofweek, TIMESTAMP 'epoch' + e.ts/1000 *INTERVAL '1 second') = 6.0\n",
    "            )\n",
    "        THEN 'no'\n",
    "        ELSE 'yes'\n",
    "        END\n",
    "        AS weekday\n",
    "FROM event_stage e\n",
    "WHERE e.page = 'NextSong'\n",
    "ORDER BY time_key ASC;\n",
    "\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserting data...\n"
     ]
    }
   ],
   "source": [
    "# Execute Star Schema Table SQL Queries\n",
    "\n",
    "insert_table_queries = [songplay_table_insert, user_table_insert, song_table_insert, artist_table_insert, time_table_insert]\n",
    "print(\"Inserting data...\")\n",
    "for query in insert_table_queries:\n",
    "    cur.execute(query)\n",
    "    conn.commit()\n",
    "print(\"Inserting data complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
